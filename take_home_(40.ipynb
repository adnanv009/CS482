{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7U4gA4M9MQV"
      },
      "source": [
        "##  Problem Set 1: Clustering streaming data  (take home midterm problem) - 40 points\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In your NYC taxi trip data assignment, you have built a parquet dataset that contains all the nyc taxi trips. The data stream is in reality available through kafka / nats  consumers but you can [stream the dataset you have uploaded to Hugging Face](https://huggingface.co/docs/datasets/en/stream) to process it through a _streaming_ clustering algorithm that can cluster the pickup and drop off trips into different geographical areas.\n",
        "\n",
        "### PS1-1 Features (5 points)\n",
        "\n",
        "You will select the features that allow you to solve the problem - consult [this kaggle notebook](https://www.kaggle.com/code/danielviray/clustering-by-district-using-k-means-algorithm/report) to see the required visualization of the produced clusters.\n",
        "\n",
        "![](clustering-outcome.png)\n",
        "\n",
        "Please note that this is an example of a clustering and since you may be dealing with potentially more areas in your dataset the number of cluster may be larger.  \n",
        "\n",
        "### PS1-2 K-Medoids clustering algorithm (15 points)\n",
        "\n",
        "You will use the [K-medoids](https://scikit-learn-extra.readthedocs.io/en/stable/generated/sklearn_extra.cluster.KMedoids.html) algorithm (see video [here](https://www.youtube.com/watch?v=OFELCn-6r2o)) to do the actual clustering. (5 points)\n",
        "\n",
        "The Gower distance needs to be used as the distance metric - see [this](https://medium.com/analytics-vidhya/gowers-distance-899f9c4bd553) or [this](https://jamesmccaffrey.wordpress.com/2020/04/21/example-of-calculating-the-gower-distance/) reference. (5 points)\n",
        "\n",
        "Explain why we need to use the Gower distance in conjunction with K-medoids and we couldn/t use K-means for this problem. (5 points)\n",
        "\n",
        "What you will deliver: Batch version of the K-medoids algorithm that is demonstrated to work on a subset of the dataset as allowed by your computer memory.\n",
        "\n",
        "\n",
        "### PS1-3 Execution on Ray (15 points)\n",
        "\n",
        "Streaming data mining algorithms like K-medoids  is executed in the real world on top of distributed computing platforms - one of the most popular ones in the domain of machine learning is [Ray](https://docs.ray.io/en/latest/ray-core/examples/gentle_walkthrough.html). See [this video](https://www.youtube.com/watch?v=w7uPnEqYz7A) for a brief overview. Ray will allow you to parallelize the execution of the K-medoids algorithm i.e. you will see all cores of your laptop be close to have increased utilization when Ray executes your K-medoids method (or all the cores across all the servers if you had a multiple machine Ray cluster). To guide you as to what kind of parallelism you can do for this problem [see this](https://github.com/EthanWng97/ray-mapreduce-kmeans) reference.\n",
        "\n",
        "Note: Ray itself [can be orchestrated by Dagster](https://www.samsara.com/blog/building-a-modern-machine-learning-platform-with-ray/), the subject of another assignment, but to keep things simple such orchestration is not a requirement in this assignment - the emphasis is on implementation and execution of the algorithm in Ray.\n",
        "\n",
        "What you will deliver: The version of the K-medoids algorithm you implemented earlier except that now it is executed more efficiently via parallel workers/actors on a Ray cluster consisting of a single node (your computer).\n",
        "\n",
        "\n",
        "### PS1-4 Deployment (5 points)\n",
        "\n",
        "For this assignment you need to create a new directory in your github repository called `midterm-take-home` and place all the necessary files in it. A docker-based environment will need to be created in that subdir with essential for this assignment files in the python environment such as `sklearn`, `ray`, and other necessary libraries.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g_kNT-pvAMki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "import gower\n",
        "\n",
        "# Assuming you have a DataFrame `df` with relevant features\n",
        "# For the sake of demonstration, let's create a simple DataFrame with mixed data types\n",
        "data = {\n",
        "    'pickup_latitude': np.random.uniform(low=40.5, high=40.9, size=100),\n",
        "    'pickup_longitude': np.random.uniform(low=-74.0, high=-73.9, size=100),\n",
        "    'day_of_week': np.random.choice(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], size=100),\n",
        "    # Assume 'duration_minutes' is a continuous variable and 'day_of_week' is categorical\n",
        "    'duration_minutes': np.random.uniform(low=5, high=60, size=100),\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the Gower distance matrix\n",
        "distance_matrix = gower.gower_matrix(df)\n",
        "\n",
        "# Use K-Medoids with the precomputed distance matrix\n",
        "kmedoids = KMedoids(n_clusters=5, metric=\"precomputed\", random_state=42)\n",
        "kmedoids.fit(distance_matrix)\n",
        "\n",
        "# Assign clusters back to the DataFrame\n",
        "df['cluster'] = kmedoids.labels_\n",
        "\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "mhkE1E4R_YcM",
        "outputId": "4be8ba54-77ef-4f30-f592-b43f8a0d3cb9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-6-36d888776c5d>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-36d888776c5d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install scikit-learn-extra gower\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "import gower\n",
        "\n",
        "ray.init()\n",
        "\n",
        "@ray.remote\n",
        "def compute_gower_distance_subset(data_subset):\n",
        "    \"\"\"\n",
        "    Simulated task: Compute the Gower distance matrix for a subset of data.\n",
        "    In a real scenario, this function would process actual data.\n",
        "    \"\"\"\n",
        "    # This is a placeholder for the computation.\n",
        "    # Replace it with actual computation, e.g., gower.gower_matrix(data_subset)\n",
        "    distance_matrix = np.random.rand(len(data_subset), len(data_subset))\n",
        "    return distance_matrix\n",
        "\n",
        "# Assuming you have a DataFrame `df` with your data\n",
        "# For demonstration, creating a sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'pickup_latitude': np.random.uniform(low=40.5, high=40.9, size=100),\n",
        "    'pickup_longitude': np.random.uniform(low=-74.0, high=-73.9, size=100),\n",
        "    'day_of_week': np.random.choice(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], size=100),\n",
        "    'duration_minutes': np.random.uniform(low=5, high=60, size=100),\n",
        "})\n",
        "\n",
        "# Split the DataFrame into subsets for demonstration\n",
        "# In a real application, determine the best way to split your data based on its size and the available memory\n",
        "data_subsets = np.array_split(df, 10)  # Splitting into 10 subsets as an example\n",
        "\n",
        "# Submit tasks to Ray for processing\n",
        "future_results = [compute_gower_distance_subset.remote(data_subset) for data_subset in data_subsets]\n",
        "\n",
        "# Retrieve results\n",
        "distance_matrices = ray.get(future_results)\n",
        "\n",
        "# Here you would combine the results (distance matrices) and proceed with K-Medoids clustering\n",
        "# For demonstration, just print the shape of the first distance matrix\n",
        "print(distance_matrices[0].shape)\n",
        "\n",
        "# Don't forget to shutdown Ray\n",
        "ray.shutdown()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "TRRRPw7Q_7FT",
        "outputId": "d991e2cc-e5f9-4cf1-8ade-c0f91daa0cc3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ray'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bf8c7b121be6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn_extra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMedoids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the official Python base image\n",
        "FROM python:3.8-slim\n",
        "\n",
        "# Set the working directory in the container to /app\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy the current directory contents into the container at /app\n",
        "COPY . /app\n",
        "\n",
        "# Install the required packages\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Command to run the application\n",
        "CMD [\"python\", \"./clustering.py\"]\n"
      ],
      "metadata": {
        "id": "XO1DLROvAPI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}